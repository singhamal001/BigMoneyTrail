{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three types of datasets were used for relevant context generation for the rag model, News and press release data, Data regarding deals done by Indian pe/vc firms and those done by international pe/vc firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing preprocessed news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('final_news_press.csv')\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data for indian firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_files_in_folder(folder_path):\n",
    "    file_list = os.listdir(folder_path) # Read individual excel files from a specified folder\n",
    "    excel_files = [file for file in file_list if file.endswith('.xlsx') or file.endswith('.xls')]\n",
    "    dfs = [] \n",
    "    \n",
    "    # Read each Excel file into a DataFrame and append to the list\n",
    "    for file in excel_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_excel(file_path, skiprows=14) # Just extracting the tables \n",
    "        df['Institution'] = os.path.splitext(file)[0]\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df\n",
    "\n",
    "# Specify the folder path where Excel files are located\n",
    "folder_path = r\"D:\\Python\\dataset_rag\\indpe\"\n",
    "\n",
    "indian_pe = read_excel_files_in_folder(folder_path)\n",
    "indian_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_pe.drop(['MnA Deal PermId'],axis=1,inplace=True) # dropping useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_pe['Year'] = indian_pe['Investment Date'].astype(str).apply(lambda x: x[0:4])  # Adding date and time column\n",
    "indian_pe['month'] = indian_pe['Investment Date'].astype(str).apply(lambda x: x[5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign_pe = pd.read_csv(\"PE_VC Data - Sheet1.csv\") # loading already consolidated international firms data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign_pe['Year'] = foreign_pe['Investment Date'].astype(str).apply(lambda x: x[-4:])\n",
    "foreign_pe['month'] = foreign_pe['Investment Date'].astype(str).apply(lambda x: x.split('/')[0] if '/' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pevc_df = pd.concat([indian_pe,foreign_pe], ignore_index=True) # Concatenating Indian and international firms data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pevc_df.drop(['Region','Deal Id','Investment Date'],axis=1,inplace=True) # dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying geographic region for countries\n",
    "\n",
    "categories = {\n",
    "      \"North America\": [\"United States\", \"Canada\", \"Mexico\"],\n",
    "      \"Western Europe\": [\"United Kingdom\", \"Germany\", \"Sweden\", \"Netherlands\", \"Belgium\", \"Ireland\", \"Italy\", \"Portugal\", \"France\", \"Spain\", \"Switzerland\", \"Austria\", \"Luxembourg\", \"Denmark\", \"Norway\", \"Finland\", \"Czech Republic\"],\n",
    "      \"Middle East\": [\"Saudi Arabia\", \"Israel\", \"United Arab Emirates\", \"Greece\",'Turkey'],\n",
    "      \"Southern Asia\": [\"India\"],\n",
    "      \"Northern Europe\": [], \n",
    "      \"SouthEast Asia\": [\"Indonesia\", \"Singapore\", \"Philippines\",'Malaysia','Thailand','Vietnam'],\n",
    "      \"East Asia\": [\"China (Mainland)\", \"Taiwan\", \"Japan\", \"Hong Kong\",'South Korea'],\n",
    "      \"Caribbean\": [\"Antigua and Barbuda\",\"Cayman Islands\",'Bermuda'],\n",
    "      \"South America\": [\"Brazil\", \"Argentina\", \"Peru\", \"Chile\"],\n",
    "      \"Southern Europe\": [],\n",
    "      \"Western Africa\": [\"Nigeria\"],\n",
    "      \"Pacific\": [\"New Zealand\", \"Australia\"],\n",
    "      \"Eastern Europe\": [\"Russia\",'Poland','Estonia'],\n",
    "      \"Southern Africa\": [\"South Africa\"],\n",
    "      \"Eastern Africa\": [\"Kenya\"]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping each country to a geographic region\n",
    "\n",
    "def get_region(country):\n",
    "  \"\"\"\n",
    "  Maps a country name to its corresponding region from the categories dictionary.\n",
    "\n",
    "  Args:\n",
    "    country: The name of the country as a string.\n",
    "\n",
    "  Returns:\n",
    "    The region of the country, or None if not found.\n",
    "  \"\"\"\n",
    "  for region, countries in categories.items():\n",
    "    if country in countries:\n",
    "      return region\n",
    "  return None\n",
    "\n",
    "pevc_df['Region'] = pevc_df['Nation'].apply(get_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pevc_df['Institution'].unique() # List of firms in consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pevc_df['month'] = pevc_df['month'].apply(lambda x: pd.to_datetime(str(x), format='%m').strftime('%B') if pd.notnull(x) else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pevc_df['Month-Year'] = pevc_df['month'].astype(str) + ' ' + pevc_df['Year'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed News data will be appended to our pe/vc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[(news_df['company'] != 'Vanguard') & (news_df['company'] != 'JPMorgan Chase & Co.')] # Filtering the data on the basis just the selected firms\n",
    "news_df.reset_index(inplace=True)\n",
    "news_df.drop(['index'],axis  = 1,inplace=True)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.rename(columns={'company': 'Institution'}, inplace=True) # Standardising some inconsistencies\n",
    "news_df['Institution'] = news_df['Institution'].replace('BlackRock', 'Blackrock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the news data and the investment data will be merged on the basis of the name of the firm that the news is about and the month-year in which that news was released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_pevc = pd.merge(pevc_df,news_df, on=['Institution', 'Month-Year'], how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_pevc_grouped = news_pevc.groupby(['Investee Company', 'Round Equity Total, MM', 'Fund Name',\n",
    "       'TRBC Industry', 'Stage', 'Status', 'Nation', 'Institution', 'Year',\n",
    "       'month', 'Region', 'Month-Year'])['LLM snippet'].agg(lambda x: ', '.join(x.dropna())).reset_index()\n",
    "news_pevc_grouped = news_pevc_grouped.drop_duplicates() # removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is in tabular format, it is not ready to be fed into the rag model directly, therefore a method was deviced in which a general string template would be used that would convey the same information each row is conveying just in a text based sentence format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific columns that contain valuable information\n",
    "selected_columns = ['Investee Company', 'Round Equity Total, MM', 'Fund Name', 'TRBC Industry', 'Stage', 'Status', 'Nation', 'Institution', 'year', 'month', 'Region', 'Month-Year', 'LLM snippet']\n",
    "\n",
    "def generate_context_sentence(row):\n",
    "    \"\"\"\n",
    "    Generates a context string for a given DataFrame row, tailored to\n",
    "    your specific data and preferences.\n",
    "\n",
    "    Args:\n",
    "        row (pandas.Series): A row from the `df_companies` DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated context string.\n",
    "    \"\"\"\n",
    "    \n",
    "    context = f\"{row['Investee Company']} which is a startup company secured venture funding from the institutional investor {row['Fund Name']} during the {row['Stage']} stage. The company, operating in the {row['TRBC Industry']} industry and based in the nation of {row['Nation']}, received investment in month of {row['Month-Year']}. {row['Institution']} was involved in the funding round. Some news snippits about {row['Institution']} in the month of {row['Month-Year']}: {row['LLM snippet']} \"\n",
    "    \n",
    "    return context\n",
    "\n",
    "news_pevc_grouped['Context'] = news_pevc_grouped.apply(generate_context_sentence, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from this we also had overall data about for each firm on the basis of Year of investment, stage of investment, country, region and industry in which the investment was made by the firm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was loaded and preprocessed for both indian and international firms, the loading method is little different as the data was not available in the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_foreign = pd.read_excel('Firm_Investment_Profile_2024_02_17_23_23_20.xlsx', sheet_name=None)\n",
    "for key, df in df_dict_foreign.items():\n",
    "    df.rename(columns={'Company Name': 'Institution'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_files_in_folder_2(folder_path, sheet_name='Sheet1'):\n",
    "    file_list = os.listdir(folder_path) # Reading the excel files as earlier\n",
    "    \n",
    "    excel_files = [file for file in file_list if file.endswith('.xlsx') or file.endswith('.xls')]\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for file in excel_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_excel(file_path, sheet_name, skiprows=8)\n",
    "        df['Institution'] = os.path.splitext(file)[0]\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    concatenated_df = concatenated_df[concatenated_df[concatenated_df.columns[0]] != \"Total\"]\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_indian = {}\n",
    "folder_path = r\"D:\\Python\\dataset_rag\\indpe_info\"\n",
    "selected_sheet_name = ['History','Industry','Stage','Status','Nation','World_Location']  #'YourSheetName' in the function will be replaced with the actual sheet name\n",
    "for i in selected_sheet_name:\n",
    "    result_df = read_excel_files_in_folder_2(folder_path, sheet_name=i)\n",
    "    df_dict_indian[i] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_combined = {}\n",
    "\n",
    "# Iterating through the keys in both dictionaries\n",
    "for key in df_dict_indian.keys():\n",
    "    # Concatenating the corresponding DataFrames from both dictionaries\n",
    "    df_combined = pd.concat([df_dict_indian[key], df_dict_foreign[key]], ignore_index=True)\n",
    "    # Storing the concatenated DataFrame in the new dictionary\n",
    "    df_dict_combined[key] = df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the similar context generation functions in these dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Num of Investments', 'Sum of Investments, MM', 'Avg by Company, MM', 'Num of Companies']\n",
    "\n",
    "def generate_context_Stage(row):\n",
    "\n",
    "    template = '''\n",
    "    context about how has the institutional investor invested in the category of {Stage} stage investments, {Company_Name} made {Num} investments, totaling {Sum} million, averaging {Avg} million per company. {Num} companies received funding in total. This is data is about how the investor has invested across all years, regions, industries, nations, etc. and should be read separately.\n",
    "    '''\n",
    "    # Placeholders and replacements:\n",
    "    replacements = {\n",
    "        'Stage': row['Stage'],\n",
    "        'Num': row['Num of Investments'],\n",
    "        'Sum': row['Sum of Investments, MM'],\n",
    "        'Avg': row['Avg by Company, MM'],\n",
    "        'Num': row['Num of Companies'],\n",
    "        'Company_Name': row['Institution']\n",
    "    }\n",
    "\n",
    "\n",
    "    # Generating the context string:\n",
    "    context = template.format(**replacements)\n",
    "\n",
    "    return context\n",
    "\n",
    "df_dict_combined['Stage']['Stage_Context'] = df_dict_combined['Stage'].apply(generate_context_Stage, axis=1)\n",
    "df_dict_combined['Stage'].drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_history(row):\n",
    "\n",
    "    template = '''\n",
    "    context about how has the institutional investor in question invested in the year of {Year}, {Company_Name} made {Num_of_Investments} investments, totaling {Sum_of_Investments_MM} million, averaging {Avg_by_Company_MM} million per company. {Num_of_Companies} companies received funding in total. This is data is about how the investor has invested across all stages, regions, industries, nations, etc. and should be read separately.\n",
    "    '''\n",
    "    # Placeholders and replacements:\n",
    "    replacements = {\n",
    "        'Year': row['Year'],\n",
    "        'Num_of_Investments': row['Num of Investments'],\n",
    "        'Sum_of_Investments_MM': row['Sum of Investments, MM'],\n",
    "        'Avg_by_Company_MM': row['Avg by Company, MM'],\n",
    "        'Num_of_Companies': row['Num of Companies'],\n",
    "        'Company_Name': row['Institution']\n",
    "    }\n",
    "\n",
    "\n",
    "    # Generating the context string:\n",
    "    context = template.format(**replacements)\n",
    "\n",
    "    return context\n",
    "\n",
    "df_dict_combined['History']['History_Context'] = df_dict_combined['History'].apply(generate_context_history, axis=1)\n",
    "df_dict_combined['History'].drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_industry(row):\n",
    "\n",
    "    template = '''\n",
    "    context about how has the institutional investor invested in the {Investee} industry, {Company_Name} made {Num} investments, totaling {Sum} million, averaging {Avg} million per company. {Num} companies received funding in total. This is data is about how the investor has invested across all years, regions, stages, nations, etc. and should be read separately.\n",
    "    '''\n",
    "    # Placeholders and replacements:\n",
    "    replacements = {\n",
    "        'Investee': row['Investee Company TRBC Economic Sector'],\n",
    "        'Num': row['Num of Investments'],\n",
    "        'Sum': row['Sum of Investments, MM'],\n",
    "        'Avg': row['Avg by Company, MM'],\n",
    "        'Num': row['Num of Companies'],\n",
    "        'Company_Name': row['Institution']\n",
    "    }\n",
    "\n",
    "\n",
    "    # Generating the context string:\n",
    "    context = template.format(**replacements)\n",
    "\n",
    "    return context\n",
    "\n",
    "df_dict_combined['Industry']['Industry_Context'] = df_dict_combined['Industry'].apply(generate_context_industry, axis=1)\n",
    "df_dict_combined['Industry'].drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_combined['Industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_nation(row):\n",
    "\n",
    "    template = '''\n",
    "    context about how has the institutional investor invested in the country of {Nation}, {Company_Name} made {Num} investments, totaling {Sum} million, averaging {Avg} million per company. {Num} companies received funding in total. This is data is about how the investor has invested across all years, regions, industries, stages, etc. and should be read separately.\n",
    "    '''\n",
    "    # Placeholders and replacements:\n",
    "    replacements = {\n",
    "        'Nation': row['Investee Company Nation'],\n",
    "        'Num': row['Num of Investments'],\n",
    "        'Sum': row['Sum of Investments, MM'],\n",
    "        'Avg': row['Avg by Company, MM'],\n",
    "        'Num': row['Num of Companies'],\n",
    "        'Company_Name': row['Institution']\n",
    "    }\n",
    "\n",
    "\n",
    "    # Generating the context string:\n",
    "    context = template.format(**replacements)\n",
    "\n",
    "    return context\n",
    "\n",
    "df_dict_combined['Nation']['Nation_Context'] = df_dict_combined['Nation'].apply(generate_context_nation, axis=1)\n",
    "df_dict_combined['Nation'].drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_World_Location(row):\n",
    "\n",
    "    template = '''\n",
    "    context about how has the institutional investor in question invested in the region of {World_Location}, {Company_Name} made {Num_of_Investments} investments, totaling {Sum_of_Investments_MM} million, averaging {Avg_by_Company_MM} million per company. {Num_of_Companies} companies received funding in total. This is data is about how the investor has invested across all years, stages, industries, nations, etc. and should be read separately.\n",
    "    '''\n",
    "    # Placeholders and replacements:\n",
    "    replacements = {\n",
    "        'World_Location': row['Investee Company World Sub Location'],\n",
    "        'Num_of_Investments': row['Num of Investments'],\n",
    "        'Sum_of_Investments_MM': row['Sum of Investments, MM'],\n",
    "        'Avg_by_Company_MM': row['Avg by Company, MM'],\n",
    "        'Num_of_Companies': row['Num of Companies'],\n",
    "        'Company_Name': row['Institution']\n",
    "    }\n",
    "\n",
    "\n",
    "    # Generating the context string:\n",
    "    context = template.format(**replacements)\n",
    "\n",
    "    return context\n",
    "\n",
    "df_dict_combined['World_Location']['World_Location_Context'] = df_dict_combined['World_Location'].apply(generate_context_World_Location, axis=1)\n",
    "df_dict_combined['World_Location'].drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_combined['History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_pevc_grouped.to_csv('prelim.csv') # Saving the dataframe in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Investee Company', 'TRBC Industry', 'Stage', 'Status', 'Nation', 'Institution', 'Year', 'month', 'Region', 'Month-Year']\n",
    "news_pevc_grouped['Context key'] = news_pevc_grouped[selected_columns].astype(str).agg(' - '.join, axis=1) # Creating a new column that would hold the keywords used in each context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_pevc_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_pevc_grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_combined.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging each of the summary dataframe with the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hist_merge = pd.merge(\n",
    "    news_pevc_grouped.astype({'Institution': str, 'Year': str}),\n",
    "    df_dict_combined['History'].astype({'Institution': str, 'Year': str}),\n",
    "    on=['Institution', 'Year'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind_merge = pd.merge(\n",
    "    Hist_merge.astype({'Institution': str, 'TRBC Industry': str}),\n",
    "    df_dict_combined['Industry'].astype({'Institution': str, 'Investee Company TRBC Economic Sector': str}),\n",
    "    left_on=['Institution', 'TRBC Industry'],\n",
    "    right_on=['Institution', 'Investee Company TRBC Economic Sector'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage_merge = pd.merge(\n",
    "    Ind_merge.astype({'Institution': str, 'Stage': str}),\n",
    "    df_dict_combined['Stage'].astype({'Institution': str, 'Stage': str}),\n",
    "    left_on=['Institution', 'Stage'],\n",
    "    right_on=['Institution', 'Stage'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation_merge = pd.merge(\n",
    "    Stage_merge.astype({'Institution': str, 'Nation': str}),\n",
    "    df_dict_combined['Nation'].astype({'Institution': str, 'Investee Company Nation': str}),\n",
    "    left_on=['Institution', 'Nation'],\n",
    "    right_on=['Institution', 'Investee Company Nation'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_merge = pd.merge(\n",
    "    Nation_merge.astype({'Institution': str, 'Region': str}),\n",
    "    df_dict_combined['World_Location'].astype({'Institution': str, 'Investee Company World Sub Location': str}),\n",
    "    left_on=['Institution', 'Region'],\n",
    "    right_on=['Institution', 'Investee Company World Sub Location'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = Final_merge[['Context key','Context','History_Context','Industry_Context','Stage_Context','Nation_Context','World_Location_Context']] # retaing just textual context columns for rag model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df.to_csv('Combined.csv') # saving in csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a single string that holds all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df['Combined_Context'] = context_df.apply(lambda row: ' '.join(row[['Context', 'History_Context', 'Industry_Context', 'Stage_Context', 'Nation_Context', 'World_Location_Context']].astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizing the data that will be used for our rag model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fin_df = context_df[['Combined_Context','Context key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fin_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fin_df.to_csv('Final_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fin_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
